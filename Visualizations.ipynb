{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc95f85-a550-4364-9969-42d6ff454489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:00:56.394794Z",
     "iopub.status.busy": "2025-11-02T11:00:56.394794Z",
     "iopub.status.idle": "2025-11-02T11:00:57.323126Z",
     "shell.execute_reply": "2025-11-02T11:00:57.323126Z",
     "shell.execute_reply.started": "2025-11-02T11:00:56.394794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded. Albumentations version: 1.3.1\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: Imports ---\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "print(f\"Imports loaded. Albumentations version: {A.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169302fe-32b2-468c-ade7-ecd740057155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:01:04.099439Z",
     "iopub.status.busy": "2025-11-02T11:01:04.099439Z",
     "iopub.status.idle": "2025-11-02T11:01:04.117465Z",
     "shell.execute_reply": "2025-11-02T11:01:04.116468Z",
     "shell.execute_reply.started": "2025-11-02T11:01:04.099439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths and parameters set.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Setup Paths and Parameters ---\n",
    "\n",
    "# Path to the 25 example images\n",
    "image_dir = r'C:\\Users\\dadab\\Desktop\\AUG paper\\Split_Dataset\\examples'\n",
    "\n",
    "# Path to save the stacked comparison images\n",
    "output_dir = r'C:\\Users\\dadab\\Desktop\\AUG paper\\aug_visual_results'\n",
    "\n",
    "# BGR mean value from the config (for fill)\n",
    "mean_val = [123.675, 116.28, 103.53]\n",
    "\n",
    "# The standard 'Resize' operation from the baseline\n",
    "# Replicates mmdet's Resize(scale=(1333, 800), keep_ratio=True)\n",
    "resize_op = A.LongestMaxSize(max_size=1333, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "print(\"Paths and parameters set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6dbaf7-b36a-454f-a4e5-cca64cdf87d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:01:09.295915Z",
     "iopub.status.busy": "2025-11-02T11:01:09.294915Z",
     "iopub.status.idle": "2025-11-02T11:01:09.305972Z",
     "shell.execute_reply": "2025-11-02T11:01:09.305972Z",
     "shell.execute_reply.started": "2025-11-02T11:01:09.295915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Helper Function ---\n",
    "\n",
    "def create_and_save_comparison(original_img, augmented_img, folder_path, filename):\n",
    "    \"\"\"\n",
    "    Stacks an original and augmented image vertically and saves the result.\n",
    "    Original (top), Augmented (bottom).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure images are 8-bit unsigned integers\n",
    "        original_img = original_img.astype(np.uint8)\n",
    "        augmented_img = augmented_img.astype(np.uint8)\n",
    "\n",
    "        # Get augmented image dimensions\n",
    "        h_aug, w_aug, _ = augmented_img.shape\n",
    "        \n",
    "        # Resize original image to the *exact* size as the augmented image\n",
    "        original_resized = cv2.resize(original_img, (w_aug, h_aug), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        # Stack them vertically\n",
    "        comparison_image = cv2.vconcat([original_resized, augmented_img])\n",
    "        \n",
    "        # Create the destination folder if it doesn't exist\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        \n",
    "        # Save the final comparison image\n",
    "        save_path = os.path.join(folder_path, filename)\n",
    "        cv2.imwrite(save_path, comparison_image)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"Helper function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb6c82b-a113-4619-93f0-643cf17b4faf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:01:14.166587Z",
     "iopub.status.busy": "2025-11-02T11:01:14.166587Z",
     "iopub.status.idle": "2025-11-02T11:01:14.378552Z",
     "shell.execute_reply": "2025-11-02T11:01:14.377550Z",
     "shell.execute_reply.started": "2025-11-02T11:01:14.166587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 25 images from C:\\Users\\dadab\\Desktop\\AUG paper\\Split_Dataset\\examples\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Load Images ---\n",
    "\n",
    "original_images = []\n",
    "# List all files in the image directory\n",
    "image_filenames = os.listdir(image_dir)\n",
    "\n",
    "for img_file in image_filenames:\n",
    "    # Ensure the file is an image\n",
    "    if img_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        # Read the image using OpenCV\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            # Store the image and its filename\n",
    "            original_images.append({'img': img, 'filename': img_file})\n",
    "\n",
    "print(f\"Loaded {len(original_images)} images from {image_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3faa74f-fb81-4b18-be18-4d4bb9c75c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:01:19.925221Z",
     "iopub.status.busy": "2025-11-02T11:01:19.925221Z",
     "iopub.status.idle": "2025-11-02T11:01:19.941382Z",
     "shell.execute_reply": "2025-11-02T11:01:19.940381Z",
     "shell.execute_reply.started": "2025-11-02T11:01:19.925221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual MixUp/CutMix functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Manual MixUp/CutMix Implementations (NumPy/CV2) ---\n",
    "# These functions replicate the MMDetection logic without using MMDetection.\n",
    "\n",
    "def mixup_data(img1, img2, alpha=1.0):\n",
    "    \"\"\"Applies MixUp to two images of the same size.\"\"\"\n",
    "    # Generate a blending factor from a Beta distribution\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    mixed_img = lam * img1 + (1 - lam) * img2\n",
    "    return mixed_img.astype(np.uint8)\n",
    "\n",
    "def cutmix_data(img1, img2, alpha=1.0):\n",
    "    \"\"\"Applies CutMix to two images of the same size.\"\"\"\n",
    "    h, w, _ = img1.shape\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    # Calculate box coordinates based on lambda\n",
    "    r_x = np.random.uniform(0, w)\n",
    "    r_y = np.random.uniform(0, h)\n",
    "    r_w = w * np.sqrt(1 - lam)\n",
    "    r_h = h * np.sqrt(1 - lam)\n",
    "    x1 = int(np.round(max(r_x - r_w / 2, 0)))\n",
    "    y1 = int(np.round(max(r_y - r_h / 2, 0)))\n",
    "    x2 = int(np.round(min(r_x + r_w / 2, w)))\n",
    "    y2 = int(np.round(min(r_y + r_h / 2, h)))\n",
    "\n",
    "    # Create a copy and paste the patch from img2 onto img1\n",
    "    img1_cut = img1.copy()\n",
    "    img1_cut[y1:y2, x1:x2, :] = img2[y1:y2, x1:x2, :]\n",
    "    return img1_cut.astype(np.uint8)\n",
    "\n",
    "def pad_to_match(img1, img2, pad_val):\n",
    "    \"\"\"Pads two images (H, W, C) to the maximum H/W dimensions.\"\"\"\n",
    "    h1, w1, _ = img1.shape\n",
    "    h2, w2, _ = img2.shape\n",
    "    max_h = max(h1, h2)\n",
    "    max_w = max(w1, w2)\n",
    "    \n",
    "    # Pad image 1 to max H/W\n",
    "    pad_h1 = max_h - h1\n",
    "    pad_w1 = max_w - w1\n",
    "    img1_padded = cv2.copyMakeBorder(img1, 0, pad_h1, 0, pad_w1, cv2.BORDER_CONSTANT, value=pad_val)\n",
    "    \n",
    "    # Pad image 2 to max H/W\n",
    "    pad_h2 = max_h - h2\n",
    "    pad_w2 = max_w - w2\n",
    "    img2_padded = cv2.copyMakeBorder(img2, 0, pad_h2, 0, pad_w2, cv2.BORDER_CONSTANT, value=pad_val)\n",
    "    \n",
    "    return img1_padded, img2_padded\n",
    "\n",
    "print(\"Manual MixUp/CutMix functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032d2dc8-a057-4123-abf2-a99f72c870cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:03:21.518682Z",
     "iopub.status.busy": "2025-11-02T11:03:21.518682Z",
     "iopub.status.idle": "2025-11-02T11:03:21.539697Z",
     "shell.execute_reply": "2025-11-02T11:03:21.539697Z",
     "shell.execute_reply.started": "2025-11-02T11:03:21.518682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 22 Albumentations pipelines.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Define All 24 Augmentation Pipelines (Pure Albumentations) ---\n",
    "# Each pipeline replicates the *full* transform chain from training.\n",
    "# 'p=1.0' ensures the transform is applied for visualization.\n",
    "\n",
    "# Common arguments for geometric transforms (fill with mean)\n",
    "border_args = dict(border_mode=cv2.BORDER_CONSTANT, value=mean_val)\n",
    "\n",
    "experiments = {\n",
    "    # 1. Baseline: Resize only\n",
    "    'exp01_baseline': A.Compose([resize_op]),\n",
    "    \n",
    "    # --- MMDET NATIVE REPLICATIONS (applied AFTER Resize) ---\n",
    "    'exp02_hflip': A.Compose([resize_op, A.HorizontalFlip(p=1.0)]),\n",
    "    'exp03_vflip': A.Compose([resize_op, A.VerticalFlip(p=1.0)]),\n",
    "    'exp16_randomerasing': A.Compose([resize_op, A.CoarseDropout(max_holes=1, max_height=0.2, max_width=0.2, min_height=0.02, min_width=0.02, p=1.0, fill_value=mean_val)]),\n",
    "    'exp18_gridmask': A.Compose([resize_op, A.GridDropout(p=1.0, fill_value=0)]),\n",
    "\n",
    "    # --- ALBU REPLICATIONS (applied BEFORE Resize) ---\n",
    "    'exp04_rotate': A.Compose([A.Rotate(limit=90, p=1.0, **border_args), resize_op]),\n",
    "    \n",
    "    # --- FIXED: Use A.RandomScale instead of A.Scale ---\n",
    "    'exp05_scale': A.Compose([A.RandomScale(scale_limit=0.2, p=1.0, interpolation=cv2.INTER_LINEAR), resize_op]), \n",
    "    \n",
    "    'exp06_affine': A.Compose([A.Affine(scale=0.2, translate_percent=0.1, rotate=15, shear=10, p=1.0, cval=mean_val[0], mode=cv2.BORDER_CONSTANT), resize_op]),\n",
    "    'exp08_brightnesscontrast': A.Compose([A.RandomBrightnessContrast(p=1.0), resize_op]),\n",
    "    'exp09_hsv': A.Compose([A.HueSaturationValue(p=1.0), resize_op]),\n",
    "    'exp10_clahe': A.Compose([A.CLAHE(p=1.0), resize_op]),\n",
    "    'exp11_channelshuffle': A.Compose([A.ChannelShuffle(p=1.0), resize_op]),\n",
    "    'exp12_elastictransform': A.Compose([A.ElasticTransform(p=1.0, alpha=50, sigma=5, **border_args), resize_op]),\n",
    "    'exp13_griddistortion': A.Compose([A.GridDistortion(p=1.0, **border_args), resize_op]),\n",
    "    'exp14_opticaldistortion': A.Compose([A.OpticalDistortion(p=1.0, **border_args), resize_op]),\n",
    "    'exp15_piecewiseaffine': A.Compose([A.PiecewiseAffine(p=1.0, cval=mean_val[0]), resize_op]),\n",
    "    'exp17_cutout': A.Compose([A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=mean_val, p=1.0), resize_op]),\n",
    "    'exp19_gaussnoise': A.Compose([A.GaussNoise(p=1.0), resize_op]),\n",
    "    'exp20_motionblur': A.Compose([A.MotionBlur(blur_limit=(3, 11), p=1.0), resize_op]),\n",
    "    'exp21_gaussianblur': A.Compose([A.GaussianBlur(blur_limit=(3, 7), p=1.0), resize_op]),\n",
    "    'exp22_medianblur': A.Compose([A.MedianBlur(blur_limit=(3, 7), p=1.0), resize_op]),\n",
    "    \n",
    "    # --- SPECIAL CASE (REPLACES Resize) ---\n",
    "    'exp07_randomresizedcrop': A.Compose([\n",
    "        A.RandomResizedCrop(height=800, width=1333, scale=(0.5, 2.0), ratio=(0.75, 1.33), p=1.0)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(f\"Defined {len(experiments)} Albumentations pipelines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5219b1eb-39ee-45ec-b1e5-fe7910b73bac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:03:24.858163Z",
     "iopub.status.busy": "2025-11-02T11:03:24.857163Z",
     "iopub.status.idle": "2025-11-02T11:03:50.533254Z",
     "shell.execute_reply": "2025-11-02T11:03:50.532252Z",
     "shell.execute_reply.started": "2025-11-02T11:03:24.858163Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Experiments: 100%|██████████████████████████████████████████████████████████| 22/22 [00:25<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Standard augmentations complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Run Visualization (Standard Augmentations) ---\n",
    "\n",
    "# This cell processes all pipelines defined in Cell 6\n",
    "standard_experiments = {k: v for k, v in experiments.items()}\n",
    "\n",
    "for exp_name, pipeline in tqdm(standard_experiments.items(), desc=\"Processing Experiments\"):\n",
    "    \n",
    "    # Process all 25 images for this experiment\n",
    "    for img_data in original_images:\n",
    "        original_img = img_data['img'].copy()\n",
    "        \n",
    "        # Apply the full augmentation pipeline\n",
    "        try:\n",
    "            augmented_data = pipeline(image=original_img)\n",
    "            augmented_img = augmented_data['image']\n",
    "            \n",
    "            # --- Save the comparison ---\n",
    "            save_folder = os.path.join(output_dir, exp_name)\n",
    "            save_filename = f\"{os.path.splitext(img_data['filename'])[0]}_compare.jpg\"\n",
    "            \n",
    "            create_and_save_comparison(original_img, augmented_img, save_folder, save_filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in pipeline {exp_name} for image {img_data['filename']}: {e}\")\n",
    "\n",
    "print(\"--- Standard augmentations complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11449113-17e2-4e77-bd2a-1cd248df2e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-02T11:03:58.766070Z",
     "iopub.status.busy": "2025-11-02T11:03:58.765065Z",
     "iopub.status.idle": "2025-11-02T11:04:00.124094Z",
     "shell.execute_reply": "2025-11-02T11:04:00.123093Z",
     "shell.execute_reply.started": "2025-11-02T11:03:58.766070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing exp23_mixup ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing exp23_mixup: 100%|██████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing exp24_cutmix ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing exp24_cutmix: 100%|█████████████████████████████████████████████████████████| 25/25 [00:00<00:00, 41.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MixUp/CutMix augmentations complete ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 8: Run Visualization (MixUp & CutMix) ---\n",
    "\n",
    "# These two are special cases and use the manual functions from Cell 5\n",
    "mosaic_experiments = [\n",
    "    ('exp23_mixup', mixup_data),\n",
    "    ('exp24_cutmix', cutmix_data)\n",
    "]\n",
    "\n",
    "for exp_name, transform_func in mosaic_experiments:\n",
    "    print(f\"--- Processing {exp_name} ---\")\n",
    "    \n",
    "    for i in tqdm(range(len(original_images)), desc=f\"Processing {exp_name}\"):\n",
    "        # Get image 1 and image 2\n",
    "        img_data1 = original_images[i]\n",
    "        # Get the next image (or loop back to the first for the last image)\n",
    "        img_data2 = original_images[(i + 1) % len(original_images)] \n",
    "\n",
    "        original_img1 = img_data1['img'].copy()\n",
    "        original_img2 = img_data2['img'].copy()\n",
    "\n",
    "        # --- Apply the pipeline ---\n",
    "        # 1. Resize both images first (replicating the training pipeline)\n",
    "        img1_resized = resize_op(image=original_img1)['image']\n",
    "        img2_resized = resize_op(image=original_img2)['image']\n",
    "        \n",
    "        # 2. Pad images to match max H/W (replicating batch padding)\n",
    "        img1_padded, img2_padded = pad_to_match(img1_resized, img2_resized, mean_val)\n",
    "        \n",
    "        # 3. Apply the manual MixUp/CutMix function\n",
    "        augmented_img = transform_func(img1_padded, img2_padded)\n",
    "\n",
    "        # --- Save the comparison ---\n",
    "        save_folder = os.path.join(output_dir, exp_name)\n",
    "        save_filename = f\"{os.path.splitext(img_data1['filename'])[0]}_compare.jpg\"\n",
    "        \n",
    "        # Compare the *original* image 1 to the final mixed result\n",
    "        create_and_save_comparison(original_img1, augmented_img, save_folder, save_filename)\n",
    "\n",
    "print(\"--- MixUp/CutMix augmentations complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118336f-f7d9-46e7-bd77-747620ee15dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMDetection Stable",
   "language": "python",
   "name": "mmdet-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
